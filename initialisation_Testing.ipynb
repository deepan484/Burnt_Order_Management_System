{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **This entire ipynb was just me figuring out the best way to approach this assesment and creating the vector data base !!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initilaization and Creating the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'product-embedding' created.\n",
      "Embeddings and metadata prepared.\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pinecone_api_key = os.getenv('pincone_key')\n",
    "hugging_face_api = os.getenv('hugging_face_key')\n",
    "\n",
    "# Initialize Pinecone client\n",
    "pc = Pinecone(api_key = pinecone_api_key)\n",
    "\n",
    "# Define the index name and embedding dimension (768 for BGE embeddings)\n",
    "index_name = \"product-embedding\"\n",
    "dimension = 1024  #rs\n",
    "\n",
    "# Check if the index already exists, if not, create it\n",
    "if index_name not in pc.list_indexes().names():\n",
    "\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=dimension,\n",
    "        metric=\"cosine\",  \n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",  \n",
    "            region=\"us-east-1\"  \n",
    "        ),\n",
    "        deletion_protection=\"disabled\"  \n",
    "    )\n",
    "    print(f\"Index '{index_name}' created.\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists.\")\n",
    "\n",
    "model_name = \"BAAI/bge-large-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to convert text to embedding (vector)\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "  \n",
    "    embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    return embedding\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"products.csv\")\n",
    "\n",
    "embeddings = []\n",
    "metadata = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    product_description = row['product_description']\n",
    "    \n",
    "\n",
    "    embedding = get_embedding(product_description)  \n",
    "    \n",
    " \n",
    "    product_metadata = {\n",
    "        'product_code': row['product_code'],\n",
    "        'product_price': row['product_price'],\n",
    "        'product_unit': row['product_unit']\n",
    "    }\n",
    "    \n",
    "    embeddings.append(embedding)\n",
    "    metadata.append(product_metadata)\n",
    "    \n",
    "print(\"Embeddings and metadata prepared.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upserting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings and metadata have been upserted successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "\n",
    "upsert_data = []\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    # Each upsert item consists of a unique ID (use product_id), the vector, and metadata\n",
    "    upsert_data.append((\n",
    "        str(df['product_id'][i]),  # Unique ID (can be product_id)\n",
    "        embeddings[i],             # The embedding vector\n",
    "        metadata[i]                # The metadata dictionary\n",
    "    ))\n",
    "\n",
    "# Upsert the embeddings and metadata into Pinecone\n",
    "index.upsert(vectors=upsert_data)\n",
    "print(\"Embeddings and metadata have been upserted successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query results: {'matches': [{'id': '243',\n",
      "              'metadata': {'product_code': 'BMILK',\n",
      "                           'product_price': 2.5,\n",
      "                           'product_unit': 'EACH'},\n",
      "              'score': 0.932030916,\n",
      "              'values': []},\n",
      "             {'id': '308',\n",
      "              'metadata': {'product_code': 'GD202',\n",
      "                           'product_price': 0.0,\n",
      "                           'product_unit': 'CASE'},\n",
      "              'score': 0.893846929,\n",
      "              'values': []},\n",
      "             {'id': '293',\n",
      "              'metadata': {'product_code': 'EVA',\n",
      "                           'product_price': 2.0,\n",
      "                           'product_unit': 'EACH'},\n",
      "              'score': 0.88635546,\n",
      "              'values': []},\n",
      "             {'id': '280',\n",
      "              'metadata': {'product_code': 'DM100',\n",
      "                           'product_price': 1.45,\n",
      "                           'product_unit': 'PCS'},\n",
      "              'score': 0.881391823,\n",
      "              'values': []},\n",
      "             {'id': '354',\n",
      "              'metadata': {'product_code': 'MILK',\n",
      "                           'product_price': 7.5,\n",
      "                           'product_unit': 'GAL'},\n",
      "              'score': 0.876935959,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_description = \"Butter Milk\"  \n",
    "\n",
    "# Get the embedding (vector) of the sample description\n",
    "query_vector = get_embedding(sample_description)\n",
    "\n",
    "query_vector = query_vector.tolist()\n",
    "\n",
    "# Perform the query to Pinecone\n",
    "results = index.query(\n",
    "    vector=query_vector,  \n",
    "    top_k=5,              \n",
    "    include_metadata=True \n",
    ")\n",
    "\n",
    "\n",
    "print(\"Query results:\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# Initialize the client with your API key\n",
    "client = InferenceClient(api_key = hugging_face_api)\n",
    "\n",
    "# Define messages for the chat model\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the capital of France?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Call the chat completion endpoint\n",
    "try:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    # Extract and print the content\n",
    "    answer = completion.choices[0].message.content  ]\n",
    "    print(\"Answer:\", answer)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing of LLAMA model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLaMA response: - A/B loins ( Quantity: not given, omitted)\n",
      "- Canela: 2 lbs\n",
      "- Queso blanco: 1 \n",
      "- Brisket: 10 lbs\n",
      "- Mirin: 1 \n",
      "- Konbu: 5 lbs \n",
      "- Firm tofu: 3 pieces\n",
      "- Nori: 1 piece\n",
      "- Dashi mushroom: 1 bag \n",
      "- Onion beer: 1 case\n",
      "- Yuzu green: 2\n",
      "- Flat lid (cheese butter/ cream/ or cheese blan) :  3 pieces 16-24oz\n",
      "Structured result:\n",
      " A/B loins ( Quantity: not given, omitted)\n",
      " Canela: 2 lbs\n",
      " Queso blanco: 1\n",
      " Brisket: 10 lbs\n",
      " Mirin: 1\n",
      " Konbu: 5 lbs\n",
      " Firm tofu: 3 pieces\n",
      " Nori: 1 piece\n",
      " Dashi mushroom: 1 bag\n",
      " Onion beer: 1 case\n",
      " Yuzu green: 2\n",
      " Flat lid (cheese butter/ cream/ or cheese blan): 3 pieces 16-24oz\n",
      "\n",
      "JSON Output:\n",
      "{\n",
      "    \" A/B loins ( Quantity\": \"not given, omitted)\",\n",
      "    \" Canela\": \"2 lbs\",\n",
      "    \" Queso blanco\": \"1\",\n",
      "    \" Brisket\": \"10 lbs\",\n",
      "    \" Mirin\": \"1\",\n",
      "    \" Konbu\": \"5 lbs\",\n",
      "    \" Firm tofu\": \"3 pieces\",\n",
      "    \" Nori\": \"1 piece\",\n",
      "    \" Dashi mushroom\": \"1 bag\",\n",
      "    \" Onion beer\": \"1 case\",\n",
      "    \" Yuzu green\": \"2\",\n",
      "    \" Flat lid (cheese butter/ cream/ or cheese blan)\": \"3 pieces 16-24oz\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import pandas as pd\n",
    "import json  \n",
    "\n",
    "client = InferenceClient(api_key=hugging_face_api)\n",
    "\n",
    "\n",
    "user_input = \"\"\"Hey, Here's what I need for tomorrow:\n",
    "2lbs Saku tuna blocks\n",
    "2 8/12 shrimp\n",
    "2lbs canela\n",
    "1 queso blanco\n",
    "10 lbs brisket\n",
    "1 Mirin\n",
    "Konbu 5 lb\n",
    "3 house firm tofu\n",
    "1 pcs nori\n",
    "1 bag dashi mushroom\n",
    "1 case onion beer\n",
    "2 yuzu green\n",
    "3 flat lid 16/24oz\n",
    "1 cheesecloth\"\"\"\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "Please extract the grocery items and their quantities from the following text. Present them in the format:\n",
    "\n",
    "    Item: Quantity\n",
    "\n",
    "For example:\n",
    "    - Carrot: 2 lbs\n",
    "    - Tofu: 3 pcs\n",
    "\n",
    "**Guidelines for Extraction:**\n",
    "1. Only include items that are clear products with a quantity. For example: \"Carrot: 2 lbs\" or \"Tofu: 3 pcs.\"\n",
    "2. Ignore conversational filler or irrelevant details such as \"Hi, I need,\" \"I am Deepan,\" or \"I want.\" Focus only on the grocery items.\n",
    "3. If the quantity includes a size or measurement range (e.g., '8/12 shrimp' or 'flat lid 16/24 oz'), ensure it is captured correctly.\n",
    "    Example: '2 8/12 shrimp' means 2 shrimp of size 8/12, and 'flat lid 16/24 oz' means flat lids ranging from 16 oz to 24 oz.\n",
    "4. Be cautious with special phrases that might indicate quantity ranges or variations. Ensure those are captured as part of the quantity.\n",
    "\n",
    "**Input text:**\n",
    "{user_input}\n",
    "\n",
    "Please only return the extracted grocery items in the format provided (Item: Quantity). Remove any unnecessary text.\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Call the chat completion endpoint\n",
    "try:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    # Extract the response from LLaMA\n",
    "    response = completion.choices[0].message.content\n",
    "    print(\"LLaMA response:\", response)\n",
    "    \n",
    "    # Parse the structured response (assuming LLaMA provides the correct format)\n",
    "    items = {}\n",
    "    lines = response.split('\\n')\n",
    "    for line in lines:\n",
    "        if ':' in line:\n",
    "            item, quantity = line.split(':', 1)\n",
    "            item = item.strip().strip('-')  # Strip hyphens and leading/trailing whitespace\n",
    "            items[item] = quantity.strip()\n",
    "    \n",
    "    # Print the structured result\n",
    "    print(\"Structured result:\")\n",
    "    for item, quantity in items.items():\n",
    "        print(f\"{item}: {quantity}\")\n",
    "    \n",
    "    # Convert the result to JSON\n",
    "    json_output = json.dumps(items, indent=4)\n",
    "    print(\"\\nJSON Output:\")\n",
    "    print(json_output)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we have taked the code from the meta and checked it with the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLaMA response: Saku Tuna Blocks 2lbs: 1\n",
      "Shrimp 8/12: 2\n",
      "Canela 2lbs: 1\n",
      "Queso Blanco: 1\n",
      "Brisket 10lbs: 1\n",
      "Mirin: 1\n",
      "Konbu 5lb: 1\n",
      "House firm Tofu 3pcs: 1\n",
      "Nori 1 pcs: 1\n",
      "Dashi Mushroom Bag: 1\n",
      "Onion Beer Case: 1\n",
      "Yuzu green 2: 1\n",
      "Flat Lid 16/24oz: 3\n",
      "Cheesecloth: 1\n",
      "Structured result:\n",
      "Saku Tuna Blocks 2lbs: 1\n",
      "Shrimp 8/12: 2\n",
      "Canela 2lbs: 1\n",
      "Queso Blanco: 1\n",
      "Brisket 10lbs: 1\n",
      "Mirin: 1\n",
      "Konbu 5lb: 1\n",
      "House firm Tofu 3pcs: 1\n",
      "Nori 1 pcs: 1\n",
      "Dashi Mushroom Bag: 1\n",
      "Onion Beer Case: 1\n",
      "Yuzu green 2: 1\n",
      "Flat Lid 16/24oz: 3\n",
      "Cheesecloth: 1\n",
      "\n",
      "JSON Output:\n",
      "{\n",
      "    \"Saku Tuna Blocks 2lbs\": \"1\",\n",
      "    \"Shrimp 8/12\": \"2\",\n",
      "    \"Canela 2lbs\": \"1\",\n",
      "    \"Queso Blanco\": \"1\",\n",
      "    \"Brisket 10lbs\": \"1\",\n",
      "    \"Mirin\": \"1\",\n",
      "    \"Konbu 5lb\": \"1\",\n",
      "    \"House firm Tofu 3pcs\": \"1\",\n",
      "    \"Nori 1 pcs\": \"1\",\n",
      "    \"Dashi Mushroom Bag\": \"1\",\n",
      "    \"Onion Beer Case\": \"1\",\n",
      "    \"Yuzu green 2\": \"1\",\n",
      "    \"Flat Lid 16/24oz\": \"3\",\n",
      "    \"Cheesecloth\": \"1\"\n",
      "}\n",
      "\n",
      "Results for 'Saku Tuna Blocks 2lbs':\n",
      "Query results: {'matches': [{'id': '525',\n",
      "              'metadata': {'product_code': 'TUNSAKBLK',\n",
      "                           'product_price': 13.75,\n",
      "                           'product_unit': 'LB'},\n",
      "              'score': 0.951041,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "Product Code: TUNSAKBLK\n",
      "Product Description: Tuna Saku Block Aaa 12-24 - LB\n",
      "Similarity score: 0.951041\n",
      "Original Item from User Input: 'Saku Tuna Blocks 2lbs'\n",
      "Matched Product Description from CSV: 'Tuna Saku Block Aaa 12-24 - LB'\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 'Shrimp 8/12':\n",
      "Query results: {'matches': [{'id': '201',\n",
      "              'metadata': {'product_code': 'AB123',\n",
      "                           'product_price': 44.0,\n",
      "                           'product_unit': 'EACH'},\n",
      "              'score': 0.910968661,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "Product Code: AB123\n",
      "Product Description: Frozen Shrimp White 8/12 (4 Lb Box) - EACH\n",
      "Similarity score: 0.910968661\n",
      "Original Item from User Input: 'Shrimp 8/12'\n",
      "Matched Product Description from CSV: 'Frozen Shrimp White 8/12 (4 Lb Box) - EACH'\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 'Canela 2lbs':\n",
      "Query results: {'matches': [{'id': '69',\n",
      "              'metadata': {'product_code': '26',\n",
      "                           'product_price': 9.0,\n",
      "                           'product_unit': 'LB'},\n",
      "              'score': 0.929979503,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "Product Code: 26\n",
      "Product Description: Canela - LB\n",
      "Similarity score: 0.929979503\n",
      "Original Item from User Input: 'Canela 2lbs'\n",
      "Matched Product Description from CSV: 'Canela - LB'\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 'Queso Blanco':\n",
      "Query results: {'matches': [{'id': '102',\n",
      "              'metadata': {'product_code': '362',\n",
      "                           'product_price': 0.0,\n",
      "                           'product_unit': 'EACH'},\n",
      "              'score': 0.917414784,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "Product Code: 362\n",
      "Product Description: Queso Blanco 5 Lb. - EACH\n",
      "Similarity score: 0.917414784\n",
      "Original Item from User Input: 'Queso Blanco'\n",
      "Matched Product Description from CSV: 'Queso Blanco 5 Lb. - EACH'\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 'Brisket 10lbs':\n",
      "Query results: {'matches': [{'id': '403',\n",
      "              'metadata': {'product_code': 'PP20',\n",
      "                           'product_price': 5.49,\n",
      "                           'product_unit': 'LB'},\n",
      "              'score': 0.919524312,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "Product Code: PP20\n",
      "Product Description: Brisket Wagyu - LB\n",
      "Similarity score: 0.919524312\n",
      "Original Item from User Input: 'Brisket 10lbs'\n",
      "Matched Product Description from CSV: 'Brisket Wagyu - LB'\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 'Mirin':\n",
      "Query results: {'matches': [{'id': '167',\n",
      "              'metadata': {'product_code': '7601',\n",
      "                           'product_price': 76.0,\n",
      "                           'product_unit': 'BOX'},\n",
      "              'score': 0.863876581,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "Product Code: 7601\n",
      "Product Description: Alcohol Mirin (18.9L) - BOX\n",
      "Similarity score: 0.863876581\n",
      "Original Item from User Input: 'Mirin'\n",
      "Matched Product Description from CSV: 'Alcohol Mirin (18.9L) - BOX'\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 'Konbu 5lb':\n",
      "Query results: {'matches': [{'id': '149',\n",
      "              'metadata': {'product_code': '61196',\n",
      "                           'product_price': 40.0,\n",
      "                           'product_unit': 'EACH'},\n",
      "              'score': 0.954577804,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "Product Code: 61196\n",
      "Product Description: Dashi Konbu 5Lb - EACH\n",
      "Similarity score: 0.954577804\n",
      "Original Item from User Input: 'Konbu 5lb'\n",
      "Matched Product Description from CSV: 'Dashi Konbu 5Lb - EACH'\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 'House firm Tofu 3pcs':\n",
      "Query results: {'matches': [{'id': '153',\n",
      "              'metadata': {'product_code': '63386',\n",
      "                           'product_price': 16.0,\n",
      "                           'product_unit': 'CASE'},\n",
      "              'score': 0.914385498,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "Product Code: 63386\n",
      "Product Description: House Firm Tofu 12 X 14Oz - CASE\n",
      "Similarity score: 0.914385498\n",
      "Original Item from User Input: 'House firm Tofu 3pcs'\n",
      "Matched Product Description from CSV: 'House Firm Tofu 12 X 14Oz - CASE'\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 'Nori 1 pcs':\n",
      "Query results: {'matches': [{'id': '156',\n",
      "              'metadata': {'product_code': '63893',\n",
      "                           'product_price': 9.6,\n",
      "                           'product_unit': 'PCS'},\n",
      "              'score': 0.925769687,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "Product Code: 63893\n",
      "Product Description: Kizami Nori - PCS\n",
      "Similarity score: 0.925769687\n",
      "Original Item from User Input: 'Nori 1 pcs'\n",
      "Matched Product Description from CSV: 'Kizami Nori - PCS'\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 'Dashi Mushroom Bag':\n",
      "Query results: {'matches': [{'id': '367',\n",
      "              'metadata': {'product_code': 'NYM12',\n",
      "                           'product_price': 50.0,\n",
      "                           'product_unit': 'BAG'},\n",
      "              'score': 0.973318636,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "Product Code: NYM12\n",
      "Product Description: Mushroom Dashi Pack - BAG\n",
      "Similarity score: 0.973318636\n",
      "Original Item from User Input: 'Dashi Mushroom Bag'\n",
      "Matched Product Description from CSV: 'Mushroom Dashi Pack - BAG'\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 'Onion Beer Case':\n",
      "Query results: {'matches': [{'id': '159',\n",
      "              'metadata': {'product_code': '6732',\n",
      "                           'product_price': 41.9,\n",
      "                           'product_unit': 'CASE'},\n",
      "              'score': 0.922721,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "Product Code: 6732\n",
      "Product Description: Orion Beer - CASE\n",
      "Similarity score: 0.922721\n",
      "Original Item from User Input: 'Onion Beer Case'\n",
      "Matched Product Description from CSV: 'Orion Beer - CASE'\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 'Yuzu green 2':\n",
      "Query results: {'matches': [{'id': '86',\n",
      "              'metadata': {'product_code': '30515',\n",
      "                           'product_price': 3.3,\n",
      "                           'product_unit': 'EACH'},\n",
      "              'score': 0.885944486,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "Product Code: 30515\n",
      "Product Description: Yuzu Kosho Green 2.82Oz - EACH\n",
      "Similarity score: 0.885944486\n",
      "Original Item from User Input: 'Yuzu green 2'\n",
      "Matched Product Description from CSV: 'Yuzu Kosho Green 2.82Oz - EACH'\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 'Flat Lid 16/24oz':\n",
      "Query results: {'matches': [{'id': '296',\n",
      "              'metadata': {'product_code': 'F98HCF',\n",
      "                           'product_price': 54.95,\n",
      "                           'product_unit': 'EACH'},\n",
      "              'score': 0.938414097,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "Product Code: F98HCF\n",
      "Product Description: Flat Lid For 16/24Oz With 98Mm Slot (1000) Victoria Bay - EACH\n",
      "Similarity score: 0.938414097\n",
      "Original Item from User Input: 'Flat Lid 16/24oz'\n",
      "Matched Product Description from CSV: 'Flat Lid For 16/24Oz With 98Mm Slot (1000) Victoria Bay - EACH'\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 'Cheesecloth':\n",
      "Query results: {'matches': [{'id': '49',\n",
      "              'metadata': {'product_code': '2012B',\n",
      "                           'product_price': 0.0,\n",
      "                           'product_unit': 'EACH'},\n",
      "              'score': 0.913395464,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "Product Code: 2012B\n",
      "Product Description: White Bleached Cheesecloth 36 In X 80 Yards. - EACH\n",
      "Similarity score: 0.913395464\n",
      "Original Item from User Input: 'Cheesecloth'\n",
      "Matched Product Description from CSV: 'White Bleached Cheesecloth 36 In X 80 Yards. - EACH'\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import pandas as pd\n",
    "import json\n",
    "from pinecone import Pinecone\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "\n",
    "index_name = \"product-embedding\"\n",
    "dimension = 1024  # This is the size for the BGE model's output vectors\n",
    "\n",
    "# Load the Pinecone index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Load the LLaMA model\n",
    "client = InferenceClient(api_key=hugging_face_api)\n",
    "model_name = \"BAAI/bge-large-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to convert text to embedding (vector)\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    return embedding\n",
    "\n",
    "# Define the input message (user's request for groceries)\n",
    "user_input = \"\"\" Hey,Here's what I need for tomorrow:\n",
    "•\t2lbs Saku tuna blocks\n",
    "•\t2 8/12 shrimp\n",
    "•\t2lbs canela\n",
    "•\t1 queso blanco\n",
    "•\t10 lbs brisket\n",
    "•\t1 Mirin\n",
    "•\tKonbu 5lb\n",
    "•\t3 house firm tofu\n",
    "•\t1 pcs nori\n",
    "•\t1 bag dashi mushroom\n",
    "•\t1 case onion beer\n",
    "•\t2 yuzu green\n",
    "•\t3 flat lid 16/24oz\n",
    "•\t1 cheesecloth\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Create a conversation with LLaMA to extract grocery items and quantities\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "You are an AI assistant tasked with extracting grocery items and their quantities from the provided text. The response must strictly adhere to the following rules:\n",
    "\n",
    "**Output Format:**\n",
    "- [Item Name and Size/Unit]: [Quantity]\n",
    "\n",
    "**Examples:**\n",
    "- Saku Tuna Blocks 2lbs: 1\n",
    "- Shrimp 8/12: 2\n",
    "- Brisket 10lbs: 1\n",
    "- Onion Beer Case: 1\n",
    "- Dashi Mushroom Bag: 1\n",
    "\n",
    "**Important Extraction Guidelines:**\n",
    "1. **Quantity vs. Size/Unit**:\n",
    "   - If a size/unit like \"2lbs\" appears, it is always part of the item name.\n",
    "   - The quantity refers only to the **number of items** (e.g., 1 block of Saku Tuna 2lbs → `Saku Tuna Blocks 2lbs: 1`).\n",
    "   - Example:\n",
    "     - Input: \"2lbs Saku Tuna Blocks\" → Output: Saku Tuna Blocks 2lbs: 1\n",
    "     - Input: \"2 8/12 shrimp\" → Output: Shrimp 8/12: 2\n",
    "2. **Units or Packaging Types**:\n",
    "   - Include units like `case`, `bag`, `pcs`, or specific sizes (e.g., `16/24oz`) as part of the item name.\n",
    "   - Example:\n",
    "     - Input: \"1 case onion beer\" → Output: Onion Beer Case: 1\n",
    "     - Input: \"1 bag dashi mushroom\" → Output: Dashi Mushroom Bag: 1\n",
    "3. **Only Numeric Quantities in the Quantity Field**:\n",
    "   - The numeric quantity represents the count of the item, not its size or weight.\n",
    "   - Example:\n",
    "     - Input: \"10 lbs brisket\" → Output: Brisket 10lbs: 1\n",
    "4. **Exclude Filler Text**:\n",
    "   - Ignore phrases like \"Hi, I need,\" or \"Can you get me.\"\n",
    "   - Focus only on the product names and quantities.\n",
    "5. **Capture Order of Words**:\n",
    "   - If the size/unit appears before or after the item name (e.g., \"2lbs brisket\" or \"brisket 2lbs\"), treat it consistently as part of the item name.\n",
    "\n",
    "**Input Text:**\n",
    "{user_input}\n",
    "\n",
    "**Output Requirements:**\n",
    "- Each item should be on a new line in the format `[Item Name and Size/Unit]: [Quantity]`.\n",
    "- Do not add extra explanations or comments. Only provide the extracted data in the specified format.\n",
    "\n",
    "Begin extracting the grocery items and quantities.\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    # Extract the response from LLaMA\n",
    "    response = completion.choices[0].message.content\n",
    "    print(\"LLaMA response:\", response)\n",
    "    \n",
    "\n",
    "    items = {}\n",
    "    lines = response.split('\\n')\n",
    "    for line in lines:\n",
    "        if ':' in line:\n",
    "            item, quantity = line.split(':', 1)\n",
    "            # Remove leading bullet points or other unwanted characters\n",
    "            item = item.strip().strip('-').lstrip('\\u2022').strip()  \n",
    "            items[item] = quantity.strip()\n",
    "\n",
    "    # Remove the first unnecessary item from the dictionary\n",
    "    if \"Here are the extracted grocery items and their quantities\" in items:\n",
    "        del items[\"Here are the extracted grocery items and their quantities\"]\n",
    "\n",
    "    # Print the structured result\n",
    "    print(\"Structured result:\")\n",
    "    for item, quantity in items.items():\n",
    "        print(f\"{item}: {quantity}\")\n",
    "\n",
    "    # Convert the result to JSON\n",
    "    json_output = json.dumps(items, indent=4)\n",
    "    print(\"\\nJSON Output:\")\n",
    "    print(json_output)\n",
    "\n",
    "\n",
    "    # Load the products CSV file\n",
    "    df_products = pd.read_csv(\"products.csv\")\n",
    "    \n",
    "    # Now, let's convert the items (keys) into embeddings and query Pinecone\n",
    "    for item in items.keys():\n",
    "        # Convert the key (item) into an embedding\n",
    "        query_vector = get_embedding(item)\n",
    "        query_vector = query_vector.tolist()  # Convert the numpy array to a list\n",
    "        \n",
    "\n",
    "        results = index.query(\n",
    "            vector=query_vector, \n",
    "            top_k=1,              \n",
    "            include_metadata=True \n",
    "        )\n",
    "        \n",
    "        # Print the results\n",
    "        print(f\"\\nResults for '{item}':\")\n",
    "        print(\"Query results:\", results)\n",
    "\n",
    "        # Print the metadata of the top matches and fetch the product description\n",
    "        for match in results['matches']:\n",
    "            product_code = match['metadata']['product_code']  \n",
    "            print(f\"Product Code: {product_code}\")\n",
    "            \n",
    "            # Look for the product_code in the products DataFrame\n",
    "            product_row = df_products[df_products['product_code'] == product_code]\n",
    "            \n",
    "            if not product_row.empty:\n",
    "                product_description = product_row.iloc[0]['product_description']\n",
    "                print(f\"Product Description: {product_description}\")\n",
    "            else:\n",
    "                print(\"Product not found in the CSV.\")\n",
    "            \n",
    "            print(f\"Similarity score: {match['score']}\")\n",
    "            \n",
    "            # Now, let's compare the original item (from the LLaMA response) and the matched product description\n",
    "            print(f\"Original Item from User Input: '{item}'\")\n",
    "            print(f\"Matched Product Description from CSV: '{product_description}'\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import pandas as pd\n",
    "import json\n",
    "from pinecone import Pinecone\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "def backend(user_input):\n",
    "\n",
    "    # Initialize Pinecone client\n",
    "    pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "\n",
    "    index_name = \"product-embedding\"\n",
    "    dimension = 1024  \n",
    "\n",
    "\n",
    "    index = pc.Index(index_name)\n",
    "\n",
    "\n",
    "    client = InferenceClient(api_key=hugging_face_api)\n",
    "    model_name = \"BAAI/bge-large-en\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    # Function to convert text to embedding (vector)\n",
    "    def get_embedding(text):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "        return embedding\n",
    "\n",
    "  \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "    Please extract the grocery items and their quantities from the following text in the format:\n",
    "\n",
    "    Item: Quantity\n",
    "\n",
    "    For example:\n",
    "    Carrot: 2 lbs\n",
    "    Tofu: 3 pcs\n",
    "\n",
    "    Special cases to consider:\n",
    "    1. If the quantity includes a size or measurement range, like '8/12 shrimp' or 'flat lid 16/24oz', ensure it is captured correctly.\n",
    "    Example: '2 8/12 shrimp' means 2 shrimp of size 8/12, and 'flat lid 16/24 oz' means flat lids in a range of 16 oz to 24 oz.\n",
    "\n",
    "    Here is the input text:\n",
    "\n",
    "    {user_input}\n",
    "    \"\"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Call the chat completion endpoint\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "            messages=messages,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        # Extract the response from LLaMA\n",
    "        response = completion.choices[0].message.content\n",
    "        print(\"LLaMA response:\", response)\n",
    "        \n",
    "     \n",
    "        items = {}\n",
    "        lines = response.split('\\n')\n",
    "        for line in lines:\n",
    "            if ':' in line:\n",
    "                item, quantity = line.split(':', 1)\n",
    "\n",
    "                item = item.strip().strip('-').lstrip('\\u2022').strip()  \n",
    "                items[item] = quantity.strip()\n",
    "\n",
    "        # Remove the first unnecessary item from the dictionary\n",
    "        if \"Here are the extracted grocery items and their quantities\" in items:\n",
    "            del items[\"Here are the extracted grocery items and their quantities\"]\n",
    "\n",
    "        # Print the structured result\n",
    "        print(\"Structured result:\")\n",
    "        for item, quantity in items.items():\n",
    "            print(f\"{item}: {quantity}\")\n",
    "\n",
    "        # Convert the result to JSON\n",
    "        json_output = json.dumps(items, indent=4)\n",
    "        print(\"\\nJSON Output:\")\n",
    "        print(json_output)\n",
    "\n",
    "\n",
    "        # Load the products CSV file\n",
    "        df_products = pd.read_csv(\"products.csv\")\n",
    "        \n",
    "        # Now, let's convert the items (keys) into embeddings and query Pinecone\n",
    "        for item in items.keys():\n",
    "            # Convert the key (item) into an embedding\n",
    "            query_vector = get_embedding(item)\n",
    "            query_vector = query_vector.tolist()  # Convert the numpy array to a list\n",
    "            \n",
    "        \n",
    "            results = index.query(\n",
    "                vector=query_vector,  \n",
    "                top_k=5,              \n",
    "                include_metadata=True\n",
    "            )\n",
    "            \n",
    "            # Print the results\n",
    "            print(f\"\\nResults for '{item}':\")\n",
    "            print(\"Query results:\", results)\n",
    "\n",
    "            # Print the metadata of the top matches and fetch the product description\n",
    "            for match in results['matches']:\n",
    "                product_code = match['metadata']['product_code']  # Retrieve product_code from metadata\n",
    "                print(f\"Product Code: {product_code}\")\n",
    "                \n",
    "                # Look for the product_code in the products DataFrame\n",
    "                product_row = df_products[df_products['product_code'] == product_code]\n",
    "                \n",
    "                if not product_row.empty:\n",
    "                    product_description = product_row.iloc[0]['product_description']\n",
    "                    print(f\"Product Description: {product_description}\")\n",
    "                else:\n",
    "                    print(\"Product not found in the CSV.\")\n",
    "                \n",
    "                print(f\"Similarity score: {match['score']}\")\n",
    "                \n",
    "                # Now, let's compare the original item (from the LLaMA response) and the matched product description\n",
    "                print(f\"Original Item from User Input: '{item}'\")\n",
    "                print(f\"Matched Product Description from CSV: '{product_description}'\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               #Guajillo Mexicano - LB\n",
       "1                                1” Cut Beef Shank - LB\n",
       "2                 12 Oz Heavy Plastic Deli Combo - CASE\n",
       "3                     12Oz Deli Combo Containers - CASE\n",
       "4                16 Oz Heavy Plastics Deli Combo - EACH\n",
       "5                     24 Ply Cotton Butcher Twine - PCS\n",
       "6       24-32Oz To Go Microwavable Lids( Lh7200) - CASE\n",
       "7                           2Oz Plastic Ramenkin - CASE\n",
       "8                      2Oz Plastic Ramenkin Lids - CASE\n",
       "9       32Oz Deli Plastic Container Bottom (480) - EACH\n",
       "10         32Oz To Go Microwavable Bowls (M7232) - CASE\n",
       "11                                 3M Tape Green - EACH\n",
       "12              500G Ina Agar (Kona Kanten) 250G - EACH\n",
       "13             64Oz Deli Plastic Container Combo - CASE\n",
       "14            64Oz Heavy Plastic Deli Containers - CASE\n",
       "15      64Oz Heavy Plastic Deli Containers Combo - CASE\n",
       "16    720 Btl Ryujin Shuzo \"Oze No Yukidore Hiyaoros...\n",
       "17      720 Ml Btl Amabuki Gin No Kurenai Junmai - CASE\n",
       "18    720Ml Btl Senkin \"Immortal Wing\" Classic Kamen...\n",
       "19         8Oz Heavy Deli Plastic Combos(Yl2508) - CASE\n",
       "20                                         Aa Choy - LB\n",
       "21                  Aaa Grade Saku Blocks - Tuna - EACH\n",
       "22                     Agave Blue Organic 2X1Gal - CASE\n",
       "23    Air Freshener Spray 8.8 Oz Air Linen & Sky (6)...\n",
       "24                          Alcohol Mirin (18.9L) - BOX\n",
       "25                           Alcohol Sake (18.9L) - BOX\n",
       "26        Almond Sliced Natural 5 Lb Bazzini 5 Lb - CTN\n",
       "27           Almonds Shelled Whole Natural 1X5Lb - CASE\n",
       "28    Aluminum Foil 18X500 Roll With Steel Cutter Hd...\n",
       "29                  Aluminum Gyoza Vat/Bottom Lg - EACH\n",
       "Name: product_description, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"products.csv\")\n",
    "\n",
    "product = df['product_description']\n",
    "\n",
    "product[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
